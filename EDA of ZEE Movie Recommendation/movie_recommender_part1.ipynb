{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13428e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Notebook 1: Data Loading, Cleaning, EDA, Apriori Association Rules & Similarity-Based Recommender\n",
    "\n",
    "# Import necessary libraries\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mount Google Drive to access data files in Colab\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load datasets - ratings, users, movies\n",
    "ratings = pd.read_csv('/content/drive/MyDrive/Scalerdatasets/zee_rat.csv')\n",
    "users = pd.read_csv('/content/drive/MyDrive/Scalerdatasets/zee_user.csv')\n",
    "movies = pd.read_csv('/content/drive/MyDrive/Scalerdatasets/zee_movie.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Clean column names to snake_case using skimpy library for uniformity\n",
    "from skimpy import clean_columns\n",
    "movies = clean_columns(movies, case='snake')\n",
    "ratings = clean_columns(ratings, case='snake')\n",
    "users = clean_columns(users, case='snake')\n",
    "\n",
    "print(\"Column names cleaned for consistency.\")\n",
    "\n",
    "# Examine shape of datasets\n",
    "print(f\"Ratings shape: {ratings.shape}, Movies shape: {movies.shape}, Users shape: {users.shape}\")\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "print(\"Missing values in ratings:\n",
    "\", ratings.isnull().sum())\n",
    "print(\"Missing values in movies:\n",
    "\", movies.isnull().sum())\n",
    "print(\"Missing values in users:\n",
    "\", users.isnull().sum())\n",
    "\n",
    "# Remove duplicated rows in ratings if any\n",
    "ratings.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert timestamp to datetime format in ratings\n",
    "from datetime import datetime\n",
    "ratings['date'] = ratings['timestamp'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "ratings['hours'] = ratings['timestamp'].apply(lambda x: datetime.fromtimestamp(x).hour)\n",
    "\n",
    "# Merge three datasets into one DataFrame for combined analysis\n",
    "df = ratings.merge(users, on='userid', how='inner')\n",
    "df = df.merge(movies, on='movieid', how='inner')\n",
    "\n",
    "# Extract release year from movie title using regex\n",
    "df['releaseyear'] = df['title'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Display some sample entries and dataset shape\n",
    "print(df.head())\n",
    "print(f\"Merged DataFrame shape: {df.shape}\")\n",
    "\n",
    "# Exploratory Data Analysis (EDA) - Basic statistics\n",
    "print(df.describe(include=[np.number]))\n",
    "print(df['genres'].nunique())\n",
    "\n",
    "# Association rule mining with the Apriori algorithm\n",
    "# Prepare dataset by pivoting user-movie ratings into a binary matrix for Apriori\n",
    "ratings_pivot = df.pivot_table(index='userid', columns='title', values='rating').fillna(0)\n",
    "ratings_binary = ratings_pivot.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Import and use mlxtend's apriori\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Generate frequent itemsets with min support\n",
    "frequent_itemsets = apriori(ratings_binary, min_support=0.12, use_colnames=True)\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Display top association rules sorted by lift\n",
    "print(rules.sort_values('lift', ascending=False).head())\n",
    "\n",
    "# Exploding genres column to one-hot encode multiple genres\n",
    "df_exp = df.copy()\n",
    "df_exp['genres'] = df_exp['genres'].str.split('|')\n",
    "df_exp = df_exp.explode('genres')\n",
    "\n",
    "# Create a user-genre matrix for apriori on genres\n",
    "user_genre = df_exp.pivot_table(index='userid', columns='genres', values='rating', aggfunc='count').fillna(0)\n",
    "user_genre_binary = user_genre.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Generate frequent genre itemsets\n",
    "genre_itemsets = apriori(user_genre_binary, min_support=0.5, use_colnames=True)\n",
    "print(genre_itemsets.sort_values('support', ascending=False).head())\n",
    "\n",
    "# Similarity-based recommendation functions\n",
    "\n",
    "def hamming_distance(x, y):\n",
    "    \"\"\"Calculate Hamming distance between two vectors.\"\"\"\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Calculate Euclidean distance between two vectors.\"\"\"\n",
    "    return np.sqrt(np.sum((x - y)**2))\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Calculate Cosine similarity between two vectors.\"\"\"\n",
    "    dot_prod = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_prod / (norm_v1 * norm_v2)\n",
    "\n",
    "def pearson_similarity(x, y):\n",
    "    \"\"\"Calculate Pearson correlation coefficient between two vectors.\"\"\"\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    num = np.sum((x - x_mean) * (y - y_mean))\n",
    "    denom = np.sqrt(np.sum((x - x_mean) ** 2) * np.sum((y - y_mean) ** 2))\n",
    "    return num / denom\n",
    "\n",
    "def similarity_based_recommendations(matrix, movies_df, movie_id_col, similarity_func):\n",
    "    \"\"\"Generate movie recommendations based on similarity function.\"\"\"\n",
    "    ranks = []\n",
    "    for query in matrix.index[:10]:  # Example: limit to first 10 for speed\n",
    "        for candidate in matrix.index:\n",
    "            if candidate == query:\n",
    "                continue\n",
    "            dist = similarity_func(matrix.loc[query], matrix.loc[candidate])\n",
    "            ranks.append((query, candidate, dist))\n",
    "    ranks = pd.DataFrame(ranks, columns=['query', 'candidate', 'distance'])\n",
    "\n",
    "    # Join movie titles for better readability of output\n",
    "    ranks = ranks.merge(movies_df, left_on='query', right_on=movie_id_col)                  .rename(columns={'title': 'query_title'}).drop(columns=[movie_id_col])\n",
    "    ranks = ranks.merge(movies_df, left_on='candidate', right_on=movie_id_col)                  .rename(columns={'title': 'candidate_title'}).drop(columns=[movie_id_col])\n",
    "\n",
    "    # Sort by query and distance (descending for similarity, ascending for distance)\n",
    "    ranks = ranks.sort_values(['query', 'distance'], ascending=[True, False])\n",
    "    return ranks\n",
    "\n",
    "# Example usage: creating movie-genre matrix for similarity recommendations\n",
    "genre_matrix = user_genre_binary\n",
    "movies_subset = movies[['movieid', 'title']].set_index('movieid')\n",
    "\n",
    "# Recommend based on cosine similarity\n",
    "recommendations = similarity_based_recommendations(genre_matrix, movies_subset, 'movieid', cosine_similarity)\n",
    "print(recommendations.head())\n",
    "\n",
    "# End of Notebook 1\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
